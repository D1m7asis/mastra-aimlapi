---
title: "Using with AIMLAPI"
description: "Learn how to integrate AIMLAPI with Mastra"
---

import { Steps } from 'nextra/components'

# Use AIMLAPI with Mastra

Integrate AIMLAPI with Mastra to access 300+ AI models with enterprise-grade rate limits and uptime.

<Steps>
## Initialize a Mastra Project

The simplest way to get started with Mastra is to use the `mastra` CLI to initialize a new project:

```bash copy
npx create-mastra@latest
```

You'll be guided through prompts to set up your project. For this example, select:
- Name your project: my-mastra-aimlapi-app
- Components: Agents (recommended)
- For default provider, select OpenAI (recommended) - we'll configure AIMLAPI manually later
- Optionally include example code

## Configure AIMLAPI

After creating your project with `create-mastra`, you'll find a `.env` file in your project root.
Since we selected OpenAI during setup, we'll configure AIMLAPI manually:

```bash filename=".env" copy
AIMLAPI_API_KEY=
```

We remove the `@ai-sdk/openai` package from the project:

```bash copy
npm uninstall @ai-sdk/openai
```

Then, we install the `@ai-ml.api/aimlapi-vercel-ai` package:

```bash copy
npm install @ai-ml.api/aimlapi-vercel-ai
```

## Configure your Agent to use AIMLAPI

We will now configure our agent to use AIMLAPI.

```typescript filename="src/mastra/agents/assistant.ts" copy showLineNumbers {4}
import { Agent } from "@mastra/core/agent";
import { aimlapi } from "@ai-ml.api/aimlapi-vercel-ai";

export const assistant = new Agent({
    name: "assistant",
    instructions: "You are a helpful assistant.",
    model: aimlapi("gpt-4o"),
})
```

Make sure to register your agent to the Mastra instance:

```typescript filename="src/mastra/index.ts" copy showLineNumbers {4}
import { assistant } from "./agents/assistant";

export const mastra = new Mastra({
    agents: { assistant }
})
```

## Run and Test your Agent

```bash copy
npm run dev
```

This will start the Mastra development server.

You can now test your agent by visiting [http://localhost:4111](http://localhost:4111) for the playground or via the Mastra API
at [http://localhost:4111/api/agents/assistant/stream](http://localhost:4111/api/agents/assistant/stream).

</Steps>

## Advanced Configuration

For more control over your AIMLAPI requests, you can pass additional configuration options.

### Provider-wide options:

You can pass provider-wide options to the AIMLAPI provider:

```typescript filename="src/mastra/agents/assistant.ts" {6-9} copy showLineNumbers
import { Agent } from "@mastra/core/agent";
import { aimlapi } from "@ai-ml.api/aimlapi-vercel-ai";

export const assistant = new Agent({
    name: "assistant",
    instructions: "You are a helpful assistant.",
    model: aimlapi("gpt-4o", {
        baseURL: "https://api.aimlapi.com/v1",
    }),
})
```

### Model-specific options:

You can pass model-specific options to the AIMLAPI provider:

```typescript filename="src/mastra/agents/assistant.ts" {7-9} copy showLineNumbers
import { Agent } from "@mastra/core/agent";
import { aimlapi } from "@ai-ml.api/aimlapi-vercel-ai";

export const assistant = new Agent({
    name: "assistant",
    instructions: "You are a helpful assistant.",
    model: aimlapi("gpt-4o", {
        temperature: 0.7,
    }),
})
```

### Provider-specific options:

You can pass provider-specific options to the AIMLAPI provider:

```typescript copy showLineNumbers {7-11}
// Get a response with provider-specific options
const response = await assistant.generate([
  {
    role: 'system',
    content:
      'You are Chef Michel, a culinary expert specializing in ketogenic (keto) diet...',
    providerOptions: {
      aimlapi: {
        max_output_tokens: 10,
      },
    },
  },
  {
    role: 'user',
    content: 'Can you suggest a keto breakfast?',
  },
]);
```
